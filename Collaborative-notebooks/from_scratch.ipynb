{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main=pd.read_csv('data/normalized_filtered_user_listening.csv').drop(['Unnamed: 0'], axis=1)\n",
    "# df=pd.read_csv('data/user_listening.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>normalized_playcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAAHSY128F147BB5C</td>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRPGYLT128F428AD02</td>\n",
       "      <td>85c1f87fea955d09b4bec2e36aee110927aedf9a</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRWCEKE128F93191BE</td>\n",
       "      <td>bd4c6e843f00bd476847fb75c47b4fb430a06856</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRDSFKT12903CB510F</td>\n",
       "      <td>4bd88bfb25263a75bbdd467e74018f4ae570e5df</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRRELZC128E078ED67</td>\n",
       "      <td>4bd88bfb25263a75bbdd467e74018f4ae570e5df</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             track_id                                   user_id  \\\n",
       "0  TRAAHSY128F147BB5C  b80344d063b5ccb3212f76538f3d9e43d87dca9e   \n",
       "1  TRPGYLT128F428AD02  85c1f87fea955d09b4bec2e36aee110927aedf9a   \n",
       "2  TRWCEKE128F93191BE  bd4c6e843f00bd476847fb75c47b4fb430a06856   \n",
       "3  TRDSFKT12903CB510F  4bd88bfb25263a75bbdd467e74018f4ae570e5df   \n",
       "4  TRRELZC128E078ED67  4bd88bfb25263a75bbdd467e74018f4ae570e5df   \n",
       "\n",
       "   normalized_playcount  \n",
       "0                   1.0  \n",
       "1                   1.0  \n",
       "2                   1.0  \n",
       "3                   0.5  \n",
       "4                   1.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\metin\\AppData\\Local\\Temp\\ipykernel_13608\\3780139360.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['user'] = df.user_id.map(user_id_to_index)\n",
      "C:\\Users\\metin\\AppData\\Local\\Temp\\ipykernel_13608\\3780139360.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['track'] = df.track_id.map(track_id_to_index)\n"
     ]
    }
   ],
   "source": [
    "df=df_main[0:10000]\n",
    "# df.set_index([\"user_id\", \"track_id\"], inplace=True)\n",
    "# # Create a mapping from user IDs and track IDs to numeric indices\n",
    "# user_id_to_index = {user_id: i for i, user_id in enumerate(df.index.get_level_values(0).unique())}\n",
    "# track_id_to_index = {track_id: i for i, track_id in enumerate(df.index.get_level_values(1).unique())}\n",
    "\n",
    "# # Replace the strings with numeric indices\n",
    "# df['user_id'] = df.index.get_level_values(0).map(user_id_to_index)\n",
    "# df['track_id'] = df.index.get_level_values(1).map(track_id_to_index)\n",
    "\n",
    "# Create a mapping from user IDs and track IDs to numeric indices\n",
    "user_id_to_index = {user_id: i for i, user_id in enumerate(df.user_id.unique())}\n",
    "track_id_to_index = {track_id: i for i, track_id in enumerate(df.track_id.unique())}\n",
    "\n",
    "# Replace the strings with numeric indices\n",
    "df['user'] = df.user_id.map(user_id_to_index)\n",
    "df['track'] = df.track_id.map(track_id_to_index)\n",
    "\n",
    "df.set_index([\"user\", \"track\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_np=df_main\n",
    "matrix=df.pivot(index='track_id',columns='user_id',values='normalized_playcount')\n",
    "# matrix=df.pivot(index='track_id',columns='user_id',values='playcount')\n",
    "arr=np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    1, ..., 5075, 5076, 5076], dtype=int64), array([1508,   11, 1656, ...,  698,  254, 1628], dtype=int64))\n",
      "0.5\n",
      "[1.         0.5        0.4        ... 0.33333333 0.21052632 0.5       ]\n"
     ]
    }
   ],
   "source": [
    "non_nan_values = np.logical_not(np.isnan(arr))\n",
    "non_nan_indices = np.where(non_nan_values)\n",
    "non_nan_elements = arr[non_nan_indices]\n",
    "print(non_nan_indices)\n",
    "print(arr[1][11])\n",
    "print(non_nan_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "\n",
    "\"\"\"Load the user artists file and return a user-artists matrix in csr\n",
    "    fromat.\n",
    "    \"\"\"\n",
    "# user_artists = pd.read_csv(user_artists_file, sep=\"\\t\")\n",
    "# df.set_index([\"user_id\", \"track_id\"], inplace=True)\n",
    "coo = coo_matrix(\n",
    "    (\n",
    "        df.normalized_playcount.astype(float),\n",
    "        (\n",
    "            df.index.get_level_values(0),\n",
    "            df.index.get_level_values(1),\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "arrcrr=coo.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 3)\t0.5\n",
      "  (3, 4)\t1.0\n",
      "  (3, 5)\t0.25\n",
      "  (4, 6)\t0.3333333333333333\n",
      "  (4, 7)\t1.0\n",
      "  (4, 8)\t0.3333333333333333\n",
      "  (4, 9)\t0.6666666666666666\n",
      "  (5, 10)\t0.6666666666666666\n",
      "  (5, 11)\t0.3333333333333333\n",
      "  (5, 12)\t0.6666666666666666\n",
      "  (5, 13)\t0.3333333333333333\n",
      "  (5, 14)\t0.3333333333333333\n",
      "  (5, 15)\t0.6666666666666666\n",
      "  (5, 16)\t0.6666666666666666\n",
      "  (5, 17)\t1.0\n",
      "  (5, 18)\t0.3333333333333333\n",
      "  (5, 19)\t0.3333333333333333\n",
      "  (5, 20)\t0.3333333333333333\n",
      "  (6, 21)\t0.25\n",
      "  (6, 22)\t0.25\n",
      "  (6, 23)\t1.0\n",
      "  (6, 24)\t0.25\n",
      "  :\t:\n",
      "  (1871, 3729)\t0.0625\n",
      "  (1871, 5064)\t1.0\n",
      "  (1871, 5065)\t0.0625\n",
      "  (1871, 5066)\t0.0625\n",
      "  (1871, 5067)\t0.0625\n",
      "  (1872, 5068)\t1.0\n",
      "  (1872, 5069)\t0.25\n",
      "  (1873, 105)\t0.5555555555555556\n",
      "  (1873, 3812)\t1.0\n",
      "  (1873, 5070)\t0.1111111111111111\n",
      "  (1874, 328)\t0.2727272727272727\n",
      "  (1874, 1580)\t0.1818181818181818\n",
      "  (1874, 1720)\t0.7272727272727273\n",
      "  (1874, 2534)\t0.1818181818181818\n",
      "  (1874, 4586)\t0.1818181818181818\n",
      "  (1874, 5071)\t0.1818181818181818\n",
      "  (1874, 5072)\t0.2727272727272727\n",
      "  (1874, 5073)\t0.0909090909090909\n",
      "  (1874, 5074)\t1.0\n",
      "  (1875, 1359)\t1.0\n",
      "  (1875, 5075)\t0.3333333333333333\n",
      "  (1876, 170)\t1.0\n",
      "  (1876, 374)\t0.6153846153846154\n",
      "  (1876, 894)\t0.0769230769230769\n",
      "  (1876, 5076)\t0.1538461538461538\n"
     ]
    }
   ],
   "source": [
    "print(arrcrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique user count : 1877\n",
      "Unique track count : 5077\n"
     ]
    }
   ],
   "source": [
    "print('Unique user count :' , len(df['user_id'].unique()))\n",
    "print('Unique track count :' , len(df['track_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filled elements\n",
    "known_values=list(zip(np.where(~np.isnan(arr))[0],\n",
    "        np.where(~np.isnan(arr))[1]))\n",
    "\n",
    "#randomly select 30% as testing set\n",
    "lucky_draw=set(np.random.choice(range(len(known_values)),\n",
    "                 size=int(len(known_values)*0.3),\n",
    "                 p=[1/len(known_values)]*len(known_values)))\n",
    "\n",
    "unlucky_draw=[i for i in range(len(known_values)) if i not in lucky_draw]\n",
    "testing_idx=(np.where(~np.isnan(arr))[0][list(lucky_draw)],\n",
    "np.where(~np.isnan(arr))[1][list(lucky_draw)])\n",
    "training_idx=(np.where(~np.isnan(arr))[0][list(unlucky_draw)],\n",
    "np.where(~np.isnan(arr))[1][list(unlucky_draw)])\n",
    "\n",
    "#train test split\n",
    "mask=np.ones(arr.shape)\n",
    "mask[testing_idx]=np.nan\n",
    "arr_train=np.multiply(arr,mask)\n",
    "\n",
    "# Convert arr_train to CSR format\n",
    "arr_csr = csr_matrix(arr_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARSE TRIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNK SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def funk_svd_epoch_sparse(arr, miu, b_u, b_i, p_u, q_i, alpha, lambda_):\n",
    "    # initialize\n",
    "    error = 0\n",
    "\n",
    "    # only iterate known ratings\n",
    "    for i in range(arr.shape[0]):\n",
    "        for u in range(arr.shape[1]):\n",
    "            r_ui = arr[i, u]\n",
    "\n",
    "            # another way to identify nan\n",
    "            # r_ui != r_ui\n",
    "            if np.isnan(r_ui):\n",
    "                continue\n",
    "\n",
    "            # compute error\n",
    "            epsilon_ui = r_ui - miu - b_u[u] - b_i[i] - q_i[i].T @ p_u[u]\n",
    "            error += epsilon_ui**2\n",
    "\n",
    "            # update\n",
    "            b_u[u] += alpha * (epsilon_ui - lambda_ * b_u[u])\n",
    "            b_i[i] += alpha * (epsilon_ui - lambda_ * b_i[i])\n",
    "            p_u[u] += alpha * (epsilon_ui * q_i[i] - lambda_ * p_u[u])\n",
    "            q_i[i] += alpha * (epsilon_ui * p_u[u] - lambda_ * q_i[i])\n",
    "\n",
    "    return error, b_u, b_i, p_u, q_i\n",
    "\n",
    "def funk_svd_sparse(arr, miu_init=None, b_u_init=[], b_i_init=[],\n",
    "                    p_u_init=[], q_i_init=[], num_of_rank=40,\n",
    "                    alpha=0.005, lambda_=0.02, tau=0.0001,\n",
    "                    max_iter=20, diagnosis=True):\n",
    "\n",
    "    # initialize\n",
    "    stop = False\n",
    "    counter = 0\n",
    "    sse = None\n",
    "\n",
    "    # global mean\n",
    "    if not miu_init:\n",
    "        # miu = arr[~np.isnan(arr)].mean()\n",
    "        miu = arr.mean()\n",
    "    else:\n",
    "        miu = miu_init\n",
    "\n",
    "    # user baseline\n",
    "    if len(b_u_init) == 0:\n",
    "        b_u = np.zeros(arr.shape[1])\n",
    "    else:\n",
    "        b_u = b_u_init\n",
    "\n",
    "    # item baseline\n",
    "    if len(b_i_init) == 0:\n",
    "        b_i = np.zeros(arr.shape[0])\n",
    "    else:\n",
    "        b_i = b_i_init\n",
    "\n",
    "    # user latent factors\n",
    "    if len(p_u_init) == 0:\n",
    "        p_u = np.zeros((arr.shape[1], num_of_rank))\n",
    "        p_u.fill(0.1)\n",
    "    else:\n",
    "        p_u = p_u_init\n",
    "\n",
    "    # item latent factors\n",
    "    if len(q_i_init) == 0:\n",
    "        q_i = np.zeros((arr.shape[0], num_of_rank))\n",
    "        q_i.fill(0.1)\n",
    "    else:\n",
    "        q_i = q_i_init\n",
    "\n",
    "    # gradient descent\n",
    "    while not stop:\n",
    "\n",
    "        error, b_u, b_i, p_u, q_i = funk_svd_epoch_sparse(arr, miu,\n",
    "                                                          b_u, b_i,\n",
    "                                                          p_u, q_i,\n",
    "                                                          alpha, lambda_)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        # maximum number of epoch\n",
    "        if counter >= max_iter:\n",
    "            stop = True\n",
    "            if diagnosis:\n",
    "                print('Not converged.',\n",
    "                      'Consider increasing the number of iterations or tolerance')\n",
    "\n",
    "        # use sum of squared error to determine if converged\n",
    "        sse_prev = sse\n",
    "        sse = error\n",
    "        if sse_prev and abs(sse / sse_prev - 1) <= tau:\n",
    "            stop = True\n",
    "            if diagnosis:\n",
    "                print(f'{counter} iterations to reach convergence\\n')\n",
    "\n",
    "    return b_u, b_i, p_u, q_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use numba to dramatically boost the speed of linear algebra\n",
    "#this will be a lot faster than surprise library\n",
    "@numba.njit\n",
    "def funk_svd_epoch(arr,miu,b_u,b_i,p_u,q_i,alpha,lambda_):\n",
    "    \n",
    "    #initialize\n",
    "    error=0\n",
    "    \n",
    "    #only iterate known ratings\n",
    "    for i in range(arr.shape[0]):\n",
    "        for u in range(arr.shape[1]):\n",
    "            r_ui=arr[i,u]\n",
    "            \n",
    "            #another way to identify nan\n",
    "            #r_ui!=r_ui\n",
    "            if np.isnan(r_ui):\n",
    "                continue\n",
    "\n",
    "            #compute error\n",
    "            epsilon_ui=r_ui-miu-b_u[u]-b_i[i]-q_i[i].T@p_u[u]\n",
    "            error+=epsilon_ui**2\n",
    "\n",
    "            #update\n",
    "            b_u[u]+=alpha*(epsilon_ui-lambda_*b_u[u])\n",
    "            b_i[i]+=alpha*(epsilon_ui-lambda_*b_i[i])\n",
    "            p_u[u]+=alpha*(epsilon_ui*q_i[i]-lambda_*p_u[u])\n",
    "            q_i[i]+=alpha*(epsilon_ui*p_u[u]-lambda_*q_i[i])\n",
    "    \n",
    "    return error,b_u,b_i,p_u,q_i\n",
    "\n",
    "#svd inspired latent factor model by simon funk\n",
    "def funk_svd(arr,miu_init=None,b_u_init=[],b_i_init=[],\n",
    "             p_u_init=[],q_i_init=[],num_of_rank=40,\n",
    "             alpha=0.005,lambda_=0.02,tau=0.0001,\n",
    "             max_iter=20,diagnosis=True\n",
    "             ):\n",
    "\n",
    "    #initialize\n",
    "    stop=False\n",
    "    counter=0\n",
    "    sse=None\n",
    "    \n",
    "    #global mean\n",
    "    if not miu_init:       \n",
    "        miu=arr[~np.isnan(arr)].mean()\n",
    "    else:\n",
    "        miu=miu_init\n",
    "        \n",
    "    #user baseline\n",
    "    if len(b_u_init)==0:\n",
    "        b_u=np.zeros(arr.shape[1])\n",
    "    else:\n",
    "        b_u=b_u_init\n",
    "    \n",
    "    #item baseline\n",
    "    if len(b_i_init)==0:\n",
    "        b_i=np.zeros(arr.shape[0])\n",
    "    else:\n",
    "        b_i=b_i_init\n",
    "        \n",
    "    #user latent factors\n",
    "    if len(p_u_init)==0:\n",
    "        p_u=np.zeros((arr.shape[1],num_of_rank))\n",
    "        p_u.fill(0.1)\n",
    "    else:\n",
    "        p_u=p_u_init\n",
    "    \n",
    "    #item latent factors\n",
    "    if len(q_i_init)==0:\n",
    "        q_i=np.zeros((arr.shape[0],num_of_rank))\n",
    "        q_i.fill(0.1)\n",
    "    else:\n",
    "        q_i=q_i_init\n",
    "    \n",
    "    #gradient descent\n",
    "    while not stop:\n",
    "        \n",
    "        error,b_u,b_i,p_u,q_i=funk_svd_epoch(arr,miu,\n",
    "                                             b_u,b_i,\n",
    "                                             p_u,q_i,\n",
    "                                             alpha,lambda_)\n",
    "\n",
    "        counter+=1\n",
    "\n",
    "        #maximum number of epoch\n",
    "        if counter>=max_iter:\n",
    "            stop=True\n",
    "            if diagnosis:\n",
    "                print('Not converged.',\n",
    "                      'Consider increase number of iterations or tolerance')\n",
    "                \n",
    "        #use sum of squared error to determine if converged\n",
    "        sse_prev=sse\n",
    "        sse=error\n",
    "        if sse_prev and abs(sse/sse_prev-1)<=tau:\n",
    "            stop=True\n",
    "            if diagnosis:\n",
    "                print(f'{counter} iterations to reach convergence\\n')\n",
    "\n",
    "    return b_u,b_i,p_u,q_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\metin\\AppData\\Local\\Temp\\ipykernel_13608\\3771288649.py (1)\u001b[0m\n\u001b[1m\nFile \"..\\..\\AppData\\Local\\Temp\\ipykernel_13608\\3771288649.py\", line 1:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m \n\nThis error may have been caused by the following argument(s):\n- argument 0: \u001b[1mCannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#funk svd\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m b_u,b_i,p_u,q_i\u001b[38;5;241m=\u001b[39m\u001b[43mfunk_svd_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr_csr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_of_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_of_latent_factors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m         \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlagrange_multiplier\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_num_of_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[86], line 74\u001b[0m, in \u001b[0;36mfunk_svd_sparse\u001b[1;34m(arr, miu_init, b_u_init, b_i_init, p_u_init, q_i_init, num_of_rank, alpha, lambda_, tau, max_iter, diagnosis)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# gradient descent\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop:\n\u001b[1;32m---> 74\u001b[0m     error, b_u, b_i, p_u, q_i \u001b[38;5;241m=\u001b[39m \u001b[43mfunk_svd_epoch_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmiu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mb_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43mp_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m                                                      \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# maximum number of epoch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\metin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\core\\dispatcher.py:468\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    464\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mrstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis error may have been caused \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    465\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby the following argument(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margs_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    466\u001b[0m         e\u001b[38;5;241m.\u001b[39mpatch_message(msg)\n\u001b[1;32m--> 468\u001b[0m     \u001b[43merror_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtyping\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnsupportedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;66;03m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[0;32m    471\u001b[0m     error_rewrite(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsupported_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\metin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numba\\core\\dispatcher.py:409\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[1;34m(e, issue_type)\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\metin\\AppData\\Local\\Temp\\ipykernel_13608\\3771288649.py (1)\u001b[0m\n\u001b[1m\nFile \"..\\..\\AppData\\Local\\Temp\\ipykernel_13608\\3771288649.py\", line 1:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m \n\nThis error may have been caused by the following argument(s):\n- argument 0: \u001b[1mCannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#initialize\n",
    "num_of_latent_factors=40\n",
    "max_num_of_epoch=2500\n",
    "learning_rate=0.01\n",
    "lagrange_multiplier=0.02\n",
    "# tolerance=0.005\n",
    "tolerance=0.01\n",
    "\n",
    "#funk svd\n",
    "b_u,b_i,p_u,q_i=funk_svd_sparse(arr_csr,num_of_rank=num_of_latent_factors,\n",
    "         alpha=learning_rate,\n",
    "         lambda_=lagrange_multiplier,tau=tolerance,\n",
    "         max_iter=max_num_of_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14963, 18657)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute global mean\n",
    "miu=arr_train[~np.isnan(arr_train)].mean()\n",
    "\n",
    "#matrix completion\n",
    "output=miu+np.repeat(\n",
    "            b_u.reshape(1,-1),\n",
    "            arr_train.shape[0],axis=0)+np.repeat(\n",
    "            b_i.reshape(-1,1),arr_train.shape[1],axis=1)+q_i@p_u.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61196735, 0.42546818, 0.48176674, ..., 0.62387674, 0.59229196,\n",
       "       0.38357858])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91359751 0.89740565 0.88965822 0.88705654 0.87544146 0.85904533\n",
      " 0.85328714 0.8530713  0.851575   0.84638962]\n",
      "[11887  3354 13271 11941 11987  8939  7887  5379  9177  4515]\n"
     ]
    }
   ],
   "source": [
    "test=12452\n",
    "n=0\n",
    "k=10\n",
    "sorted_indices=np.argsort(output[:,test])[::-1]\n",
    "top_10_indices = sorted_indices[n:k]\n",
    "print(np.sort(output[:,test])[::-1][n:k])\n",
    "print(top_10_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9135975074005096"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[11887,test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "wth=q_i@p_u.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4642951579043497\n",
      "-0.1626279594616031\n",
      "0.22913927002944032\n",
      "0.3827910389283227\n",
      "0.9135975074005096\n"
     ]
    }
   ],
   "source": [
    "# b_i[11887]\n",
    "j=11887\n",
    "wtf=np.repeat(b_u.reshape(1,-1),arr_train.shape[0],axis=0)\n",
    "why=np.repeat(b_i.reshape(-1,1),arr_train.shape[1],axis=1)\n",
    "print(miu)\n",
    "print(wtf[j,test])\n",
    "print(why[j,test])\n",
    "print(wth[j,test])\n",
    "print(miu+wtf[j,test]+why[j,test]+wth[j,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14963, 18657)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funk SVD Mean Squared Error: 0.104\n"
     ]
    }
   ],
   "source": [
    "#use mse as benchmark for comparison\n",
    "mse_funk_svd=np.square((\n",
    "    output-arr)[testing_idx]).sum()/len(arr[testing_idx])\n",
    "print('Funk SVD Mean Squared Error:',round(mse_funk_svd,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Correlation with baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain pearson correlation with baseline\n",
    "#if b_u is substituted with arr.mean(axis=1) and arr is a complete matrix\n",
    "#the function will be equivalent to np.corrcoef(arr.T)\n",
    "#except the diagonal line would be filled with zeros\n",
    "@numba.njit\n",
    "def get_pearson_corr_baseline_matrix(arr,b_u):\n",
    "\n",
    "    similarity_matrix=np.zeros((arr.shape[1],arr.shape[1]))\n",
    "    for u in range(arr.shape[1]):\n",
    "        for v in range(u+1,arr.shape[1]):\n",
    "            \n",
    "            #self correlation distorts knn selection\n",
    "            if u==v:\n",
    "                continue\n",
    "\n",
    "            #find items rated by both user u and v\n",
    "            arr_sub1=arr[:,u]\n",
    "            arr_sub2=arr[:,v]\n",
    "            set_u=np.where(~np.isnan(arr_sub1))\n",
    "            set_v=np.where(~np.isnan(arr_sub2))\n",
    "            I_uv=set(set_u[0]).intersection(set(set_v[0]))\n",
    "          \n",
    "            #avoid the case where two users havent rated any items in common\n",
    "            if len(I_uv)>0:\n",
    "                \n",
    "                #extract ratings of inner join items from user u and v\n",
    "                arr_u=arr_sub1[np.array(list(I_uv))]\n",
    "                arr_v=arr_sub2[np.array(list(I_uv))]\n",
    "                numerator=(arr_u-b_u[u]).T@(arr_v-b_u[v])\n",
    "                denominator=np.sqrt(\n",
    "                    (arr_u-b_u[u]).T@(arr_u-b_u[u]))*np.sqrt(\n",
    "                    (arr_v-b_u[v]).T@(arr_v-b_u[v]))\n",
    "                pearson_baseline=numerator/denominator\n",
    "            else:\n",
    "                pearson_baseline=0\n",
    "\n",
    "            #symmetric matrix\n",
    "            similarity_matrix[u,v]=pearson_baseline\n",
    "            similarity_matrix[v,u]=pearson_baseline\n",
    "            \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute similarity matrix\n",
    "similarity_matrix=get_pearson_corr_baseline_matrix(arr,b_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
